[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html",
    "href": "Hands-on_Ex1/Hands-on Ex1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "",
    "text": "In this hands on exercise, I learnt how to import & wrangle geospatial data using appropriate R packages"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html#getting-started",
    "href": "Hands-on_Ex1/Hands-on Ex1.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below install & load sf & tidyverse packages into the R env\n\npacman::p_load(sf,tidyverse)\n\n\nWhat is a Projected Coordinate System\nAccording to SLA SiReNT (2020), Geographical information systems’ data sets uses projected coordinate systems, such that common features can be incorporated into geographical data sets. A common coordinate system is the global WGS84 datum to map the spherical surface of the earth onto a 2 or 3 dimensional Cartesian coordinate plane for analysis.\nThe SVY21 coordinate system may be used in Singapore’s context as the datum are localized to describe the region more precisely in order to provide accurate analysis."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html#importing-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on Ex1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "1.4 Importing Geospatial Data",
    "text": "1.4 Importing Geospatial Data\nWe use st_read() to read the dataset, specifying the folder in the dsn parameter and the dataset name in the layer parameter\n\nMaster Planning Subzone dataset\n\nmpsz = st_read(dsn=\"data/geospatial\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\Allanckw\\ISSS624\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe output of the code shows that there are a total of 323 features & 15 fields of geometry type Multipolygon in the x and y dimensions.\nThe driver used is ESRI shapefile, which is a geospatial vector data format for Geographical information systems\n\n\nCycling path dataset\n\ncyclingpath = st_read(dsn=\"data/geospatial\", layer=\"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `D:\\Allanckw\\ISSS624\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 2248 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe output of the code shows that there are a total of 1625 features & 2 fields of geometry type LINESTRING in the x and y dimensions.\n\n\nPreschool dataset\nThe preschool dataset is in kml format. The difference between importing kml file and the other 2 dataset is that there is no layer information. Simply call st_read() with the filename\nKML stands for Keyhole markup language., an XML notation to express geographical annotation and visualization. (ARCGIS, 2016)\n\npreschool = st_read(\"data/geospatial/pre-schools-location-kml.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\Allanckw\\ISSS624\\Hands-on_Ex1\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe output of the code shows that there are a total of 1359 features & 2 fields of geometry type POINT in 3 dimensions (X, Y and Z). In this case preschool is in the WGS84 projected coordinate systems"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex1/Hands-on Ex1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "1.5 Checking the content of a simple Feature Data Frame",
    "text": "1.5 Checking the content of a simple Feature Data Frame\n\nst_geometry()\nst_geometry returns geometries in a list, of class 'sfc'\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\nThe output in the case returns the bounding box, projected coordinated systems and the first 5 geometries\n\n\nglimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nglimpse() displays each field’s data type, for example double precision number for X_ADDR, Y_ADDR, SHAPE_Leng, SHAPE_AREA and their corresponding available values in the dataset.\n\n\nhead()\nhead() reveals the complete information of a feature object\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html#plotting-the-geospatial-data-with-plot",
    "href": "Hands-on_Ex1/Hands-on Ex1.html#plotting-the-geospatial-data-with-plot",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "1.6 Plotting the Geospatial Data with Plot()",
    "text": "1.6 Plotting the Geospatial Data with Plot()\nWe can use plot() of R to plot the geographical objects.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nWe could call st_geometry() from within plot() to only display the geometry of the sf object\n\nplot(st_geometry(mpsz))\n\n\n\n\nIn addition, we can choose the plot the sf object by using a specific attribute like how we reference a dictionary in major programming languages with objname[\"<attributename>\"]\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html#working-with-projection",
    "href": "Hands-on_Ex1/Hands-on Ex1.html#working-with-projection",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "1.7 Working with projection",
    "text": "1.7 Working with projection\n\nAssigning EPSG Code to a simple feature data frame\nThe EPSG, or European Petroleum Survey Group, is a company that manages a database of geodetic parameters with standardized codes for coordinate systems, datums, spheroids, units.\nSometimes, importing geospatial data into R may not give an accurate analysis as the projected coordinate system is either missing or incorrect during the import system. We could use st_crs()to retrieve the coordinate system from the object.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nThe result shows that the EPSG Code is 9001, which is incorrect. The correct code for the SVY21 projected coordinate system is 3414. We could use st_set_crs() to correct the EPSG Code.\n\nmpsz3414 = st_set_crs(mpsz,3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nReprojection\nWe can see that the variable mpsz3414 has the EPSG code corrected after running st_set_crs()\nWe could however see that it returns a warning that it does not reproject data, and is asked to use st_transform()\nReprojection is the process to update the coordinates values of a dataset from one coordinate system to another coordinate system, in this case from EPSG 9001 to EPSG 3414 for the mpsz dataset.\nBelow is the code to transform the preschool dataset to the SVY21 (EPSG 3414) projected coordinate system\n\npreschool3414 = st_transform(preschool, crs=3414)\nst_crs(preschool3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html#importing-converting-aspatial-data",
    "href": "Hands-on_Ex1/Hands-on Ex1.html#importing-converting-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "1.8 Importing & Converting Aspatial Data",
    "text": "1.8 Importing & Converting Aspatial Data\nASpatial data is a dataset that contains x and y coordinates of locations’ data points. In this example, the Inside AirBnB dataset is used.\n\nImporting Aspatial data\nAs listings is in csv format, we could use read_csv() of readr package to import the dataset\n\nairbnb_listing = read_csv(\"data/aspatial/listings.csv\")\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe can use list() to display the dataset, it shows that there are 4252 rows and 16 columns, and we are interested in the longitude and latitude values\n\nlist(airbnb_listing)\n\n[[1]]\n# A tibble: 4,252 × 16\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   178\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 5 275343 Conveni… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    52\n 6 275344 15 mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    40\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    72\n 8 301247 Nice ro… 1552002 Rahul   Centra… Geylang    1.32    104. Privat…    41\n 9 324945 20 Mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n10 330089 Accomo@… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n# … with 4,242 more rows, 6 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>, and\n#   abbreviated variable names ¹​host_name, ²​neighbourhood_group,\n#   ³​neighbourhood, ⁴​latitude, ⁵​longitude, ⁶​room_type\n\n\n\n\nCreating a feature dataframe from an Aspatial data frame with st_as_sf()\nWe can use st_as_sfto create a dataframe from the longitude (x) and latitude (y) values. The EPSG 4326 code is used as the dataset is referencing WGS84 geographic coordinate system\n\nairbnb_listings_sf = st_as_sf(airbnb_listing, coords = c(\"longitude\", \"latitude\"), crs=4326)\n\nWe can then use glimpse() to displays each field’s data type & available values.\nThe results shows that the longitude and latitude values have been converted to a geometry object consisting of the longitude and latitude values as points, with both columns now dropped.\n\nglimpse(airbnb_listings_sf)\n\nRows: 4,252\nColumns: 15\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n$ geometry                       <POINT [°]> POINT (103.7852 1.33432), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex1/Hands-on Ex1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "1.9 Geoprocessing with sf package",
    "text": "1.9 Geoprocessing with sf package\n\nst_buffer()\nUsing st_buffer() to compute the 5m buffers around cycling path\n\nbuffer_cycling = st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nnQuadSegs is the number of segments per quadrant for all or per feature, the higher the number, the smoother are the curves of the buffer. Setting nQuadSeg to 1 yields straight lines with jagged edges (Pebesma, n.d)\n\n\nst_area()\nThe area of the buffer is computed by using st_area()\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nFinally, we use sum() to compute the total land area\n\nsum(buffer_cycling$AREA)\n\n1556978 [m^2]\n\n\n\n\nst_intersects()\nWe can use st_intersects() to find common data points between 2 geographical datasets. The length() function is used to find the number of points in the intersection.\nIn this case we want to identify pre-schools located inside each Planning Subzones\n\nmpsz3414$'PreSch Count'<- lengths(st_intersects(mpsz3414, preschool3414))\n\nUsing the summary function, we can find the summary statistics of the numbers of preschools of the various planning zones\n\nsummary(mpsz3414$'PreSch Count')\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   4.207   6.000  37.000 \n\n\nThe top_n function can be used to find the planning zones with the most pre-schools\n\ntop_n(mpsz3414, 1, 'PreSch Count')\n\nSimple feature collection with 323 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...            0\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...            5\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...            0\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...            2\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...            1\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...           10\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...            4\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...            4\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...            3\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...            1\n\n\n\n\nComputing Density\nDensity can be computed by first computing the area of each planning subzone.\n\nmpsz3414$Area <- mpsz3414 %>% st_area()\n\nthe mutate() function of dplyr package is then called to compute the density\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex1/Hands-on Ex1.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "1.10 Exploratory Data Analysis (EDA)",
    "text": "1.10 Exploratory Data Analysis (EDA)\n\nUsing ggplot2() to plot graphs\n\nHistogram\nThe Hist() function of R Graphics can be used to output the histogram to display the distribution of PreSch Density.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nHowever, it is not meaningful with the default labels. ggplot2 can be used to enhanced the quality of data visualization.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"White\", \n                 fill=\"Blue\") +\n  labs(title = \"Are pre-school evenly distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\nScatterplot\nWe can use ggplot and geom_point() to plot scatter diagram\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`), y=as.numeric(`PreSch Count`))) +\n       geom_point(shape=18, color=\"blue\") + \n       xlim(0,40) + ylim(0,40) +\n       labs(title=\"Relationship between Pre-school density & Pre-school count\", x=\"Pre-School Density (per km sq)\", y=\"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on Ex1.html#reference",
    "href": "Hands-on_Ex1/Hands-on Ex1.html#reference",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling",
    "section": "Reference:",
    "text": "Reference:\nARCGIS (2016), What is KML\nhttps://desktop.arcgis.com/en/arcmap/10.3/manage-data/kml/what-is-kml-.htm\nSingapore Land Authority (SLA), Singapore Satellite Positioning Reference Network (SiReNT), 2020, Plane Coordinate System - SVY21\nhttps://app.sla.gov.sg/sirent/About/PlaneCoordinateSystem\nE. Pebesma (n.d) Geometric unary operations on simple feature geometry sets\nhttps://r-spatial.github.io/sf/reference/geos_unary.html\nVirtual Surveyor (2022), What is an EPSG Code\nhttps://support.virtual-surveyor.com/en/support/solutions/articles/1000261353-what-is-an-epsg-code-#:~:text=EPSG%20stands%20for%20European%20Petroleum,spheroids%2C%20units%20and%20such%20alike."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on Ex2.html",
    "href": "Hands-on_Ex2/Hands-on Ex2.html",
    "title": "Hands-on Exercise2 - Choropleth Mapping with R",
    "section": "",
    "text": "In this hands on exercise, I learnt how to use the tmap package in R\nFirstly, we load the required packages in R\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on Ex2.html#importing-preparing-the-data",
    "href": "Hands-on_Ex2/Hands-on Ex2.html#importing-preparing-the-data",
    "title": "Hands-on Exercise2 - Choropleth Mapping with R",
    "section": "2.3 Importing & preparing the data",
    "text": "2.3 Importing & preparing the data\n\nLoading the Master Plan 2014 Subzone Boundary\n\nmpsz = st_read(dsn=\"data/geospatial\", layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\Allanckw\\ISSS624\\Hands-on_Ex2\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\nLoading the Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling dataset\n\npopData = read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nCreate a data table to break the population data into the following categories:\n\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\npopdata2020 = popData %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\n  rowSums(.[13:15]))%>%\n    mutate(`AGED`=rowSums(.[16:21])) %>%\n    mutate(`TOTAL`=rowSums(.[3:21])) %>%  \n    mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) /`ECONOMY ACTIVE`) %>%\n  \n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\nJoining attribute data & geospatial data\nBefore joining, we need to convert the PA and SZ fields to upper case. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\nWe only want Economy Active citizen in our analysis.\n\npopdata2020 = popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), .funs = funs(toupper)) %>%\n  filter('ECONOMY ACTIVE' > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 = left_join(mpsz, popdata2020, by = c(\"SUBZONE_N\" = \"SZ\"))\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on Ex2.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex2/Hands-on Ex2.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise2 - Choropleth Mapping with R",
    "section": "2.4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "2.4 Choropleth Mapping Geospatial Data Using tmap\n\nPlotting a choropleth map quickly using Quick Thematic map Plot - qtm()\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\nUsing tmap\nThe drawback of qtm() is that it is difficult to manage the appearance of individual levels. Drawing elements of tmap should be utilized to create a cartographic choropleth map as displayed below\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend using the tm_layout method\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map. They are known as Cartographic Furniture\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\n\ntm_shape(mpsz_pop2020) + \n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette =\"Reds\", \n          title=\"DEPENDENCY RATIO\") + \n  tm_layout(main.title=\"Distribution of Dependency ratio by planning subzone\", \n            main.title.position=\"center\", \n            main.title.size=1.2, \n            legend.height = 0.35, \n            legend.width = 0.35, \n            frame = TRUE) + \n  tm_borders(alpha=0.5) + \n  tm_compass(type=\"8star\", size=2) +\n  tm_scale_bar() +\n  tm_grid (alpha=0.2) +\n  tmap_style(\"classic\") +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\") \n  \n             )\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\nBase Map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a choropleth map using tm_fill() and tm_border()\ntm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nThe above shows the map drawn by using tm_fill() alone Various dependencies are accounted for when distributing the planning subzones.\nThe planning subzone boundaries will be added using tm_borders().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nThe alpha parameter is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha parameter, there are three other parameters for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\nData Classification Methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes. The breaks factor determines how a continuous variable is broken down into its respective categories\n\nVarying Style\ntmap provides a total ten data classification methods, namely (Nowosad, 2019):\n\nfixed, we need breaks for fixed value\nIn conjunction with the breaks argument, the “fixed” style permits manual choosing of the breaks.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nWe could use the quantile values to define breaks in fixed style\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5, breaks = c(0, 0.60, 0.70, 0.76, 0.90, 1.00),\n          style = \"fixed\") +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\nsd\nThe sd style determines a variable’s standard deviation and uses that number as the break width.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nequal\nThe equal style is suitable for variables with a uniform distribution and separates input values into bins of equal range. It is not advised for variables with a skewed distribution since the generated map can have a limited range of colors.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\npretty (default) This style rounds breaks into whole numbers where possible and spaces them evenly.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nquantile\nBreaks are produced by the quantile style using an equal number of features.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nkmeans\nThe breaks in the kmeans style are produced using the kmeans function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nhclust\nBreaks are made using hierarchical clustering in the hclust style.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nbclust\nThe breaks in the bclust style are produced using bagged clustering \n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\nfisher\nThe fisher style produces groups that are as homogeneous as possible.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\njenks\nThe jenks style of data analysis locates clusters of related values and emphasizes the distinctions between categories.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5, \n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nVarying n & palette\nn defines the preferred number of classes, if we were to enter a lower number, there will be less shades (or categories) vs a higher number will produce more shades (or categories)\nUsing the jenkers example, we can see using n = 3 produces only three shades, while n = 10 produces ten shades\nWe can also change the colour schemes using the palette parameter, to reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 3, palette = \"Greens\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10, palette = \"-Blues\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualization of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in 3 ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nIn this example, small multiple choropleth maps are created by defining ncols (Young and Aged) in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments (Style & palette\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nby defining a group-by variable in tm_facets(),\nIn this example, multiple small choropleth maps are created by using tm_facets().\nThis function specifies the facets, such as the number of rows and columns, the coordinate system, and whether the scales are fixed or free (i.e. independent of each other). (R Documentation, n,d)\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Reds\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\nby creating multiple stand-alone maps with tmap_arrange().\nIn this example, multiple small choropleth maps (youngmap & agedmap) are created by creating multiple stand-alone maps with tmap_arrange().\nThis function can be used to arrange custom small multiples in a grid layout. (R Documentation, n,d)\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nMapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, the selection function can be used to map spatial objects meeting the selection criterion.\nIn this example, we specify that we only want the Central Region in the mpsz_pop2020 dataset\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Reds\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on Ex2.html#reference",
    "href": "Hands-on_Ex2/Hands-on Ex2.html#reference",
    "title": "Hands-on Exercise2 - Choropleth Mapping with R",
    "section": "Reference",
    "text": "Reference\nJ. Nowosad (2019), Map coloring: the color scale styles available in the tmap package https://geocompr.github.io/post/2019/tmap-color-scales/\nR Documentation (n.d), tmap_arrange: Arrange small multiples in grid layout https://www.rdocumentation.org/packages/tmap/versions/3.3-3/topics/tmap_arrange\nR Documentation (n.d), tm_facets: Small multiples https://www.rdocumentation.org/packages/tmap/versions/3.3-3/topics/tm_facets"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on Ex3.html",
    "href": "Hands-on_Ex3/Hands-on Ex3.html",
    "title": "Hands On Exercise 2.1 - Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Hands On Exercise 3 - Global and Local Measures of Spatial Autocorrelation\nIn this hands-on exercise, we explore how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on Ex3.html#getting-started",
    "href": "Hands-on_Ex3/Hands-on Ex3.html#getting-started",
    "title": "Hands On Exercise 2.1 - Global and Local Measures of Spatial Autocorrelation",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below install & load sf, spdep, tmap & tidyverse packages into the R env\n\npacman::p_load(sf,tidyverse,spdep, tmap)\n\n\nImporting Hunan Geospatial sf\n\nhunan_sf = st_read(dsn=\"data/geospatial\", layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\Allanckw\\ISSS624\\Hands-on_Ex3\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nLoading Hunan 2012 Aspatial File in CSV\n\nhunan_GDP = read_csv(\"data/aspatial/hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on Ex3.html#joining-attribute-data-to-the-simple-feature-files",
    "href": "Hands-on_Ex3/Hands-on Ex3.html#joining-attribute-data-to-the-simple-feature-files",
    "title": "Hands On Exercise 2.1 - Global and Local Measures of Spatial Autocorrelation",
    "section": "Joining attribute data to the simple feature files",
    "text": "Joining attribute data to the simple feature files\nNext, left_join() of dplyr is used to join the geographical data and attribute table\n\nhunan = left_join(hunan_sf, hunan_GDP)\n\nJoining, by = \"County\""
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on Ex3.html#visualizing-regional-development-indicator",
    "href": "Hands-on_Ex3/Hands-on Ex3.html#visualizing-regional-development-indicator",
    "title": "Hands On Exercise 2.1 - Global and Local Measures of Spatial Autocorrelation",
    "section": "Visualizing Regional Development Indicator",
    "text": "Visualizing Regional Development Indicator\nWe will visualize a choropleth map that displays the distribution of GDPPC 2012 using the tmap package\n\nequal = tm_shape(hunan) + \n  tm_fill(\"GDPPC\", n = 5, style=\"equal\") +\n  tm_borders(alpha=0.5) + \n  tm_layout(main.title = \"Equal interval categorization\")\n\nquantile = tm_shape(hunan) + \n  tm_fill(\"GDPPC\", n = 5, style=\"quantile\") +\n  tm_borders(alpha=0.5) + \n  tm_layout(main.title = \"Equal quantile interval categorization\")\n\ntmap_arrange(equal, quantile)"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on Ex3.html#computing-spatial-autocorrelation",
    "href": "Hands-on_Ex3/Hands-on Ex3.html#computing-spatial-autocorrelation",
    "title": "Hands On Exercise 2.1 - Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Spatial Autocorrelation",
    "text": "Computing Spatial Autocorrelation\nWe learn how to compute GLOBAL spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial correlation\n\nComputing Spatial Weights\nWe need to find the spatial weights first before we can compute global spatial correlation statistics. The spatial weights is used to define the neighbourhood relationships between the geographical units\nWe use poly2nb() of spdep package to compute the contiguity weight matrix. The function builds a neighbour list based on regions with contiguous boundaries. Using queen’s contiguity weight matrix, we have\n\nwm_q = poly2nb(hunan)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nFrom the results, there are 88 regions in Hunan,\nUsing the Queen’s method, 85 of them has 11 neighbours, while only 2 of them has 1 neighbour\n\n\nBuilding the Row-standardised weights matrix\nAfter computing the spatial weights, we will need to build the row standardized weights matrix. “W” Style will be used such that each neighbouring polygon will be assigned equal weight. This is done by taking the 1/(no. of neighbours) to each neighbouring county and then summing up the weighted income values.\nAlthough this is the most logical way to summarize the neighbours’ values, there is a disadvantage in that polygons at the study area’s boundaries will base their lagged values on fewer polygons, which could lead to an over- or underestimation of the true degree of spatial autocorrelation in the data.\n\nrs_wm_q = nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrs_wm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe Null Hypothesis\nThe null hypothesis is to assume that GDPPC is randomly distributed between the different counties.\n\nComputing Spatial Autocorrelation: Moran’s I\nWe will perform Moran’s I statistical test with moran.test() of the spdep package.\n\nmoran.test(hunan$GDPPC, listw = rs_wm_q, zero.policy = TRUE, na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rs_wm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nBased on the result, we will reject the null hypothesis as the p-value is less than 0.05. In fact as the p-value is less than 0.01, we can consider that as highly significant.\nTherefore, we can conclude that the GDPPC is not randomly distributed based on Moran’s I statistics\n\n\nComputing Spatial Autocorrelation: Moran’s I with Monte Carlo simulation\nIn order to further confirm that the null hypothesis is false, we could use Monte Carlo simulation to predict potential outcomes of the event by using moran.mc() function of the spdep package. We will use 1000 simulations for this test.\n\nset.seed(908)\n\nbperm = moran.mc(hunan$GDPPC, listw = rs_wm_q, nsim=999, zero.policy = TRUE, na.action = na.omit)\n\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rs_wm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nBased on the result, we will reject the null hypothesis as the p-value is less than 0.05. In fact as the p-value is less than 0.01, we can consider that as highly significant even when the statistics is repeated 1000 times.\nTherefore, we can conclude that the GDPPC is not randomly distributed based on Moran’s I statistics with Monte Carlo simulation\n\n\nVisualizing Monte Carlo Moran’s I\nIt is always a good practice to examine the simulated Moran’s I test statistics in detail. This can be done by plotting the statistical values as a histogram by the code below:\n\nmean(bperm$res[1:999]) #compute mean\n\n[1] -0.01381501\n\nvar(bperm$res[1:999]) #compute variance\n\n[1] 0.004192274\n\nsd(bperm$res[1:999]) #compute std dev.\n\n[1] 0.06474778\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.16447 -0.06010 -0.01643 -0.01382  0.02926  0.23767 \n\n\nBuilding the histogram\n\nhist(bperm$res, freq=TRUE, breaks = 20, xlab=\"Simulated Moran's I\")\nabline(v=0, col=\"blue\")\n\n\n\n\nUsing ggplot, we can reproduce the same graph, however we need to convert the result into a data frame first\n\ndf = data.frame(bperm$res) #convert to data frame\n\nggplot(df, aes(bperm$res)) + #aes = column name\n  geom_histogram(bins=20, \n                 color=\"White\", \n                 fill=\"lightblue\") +\n  labs(x = \"Simulated Moran's I\",\n       y = \"Frequency\") +\n  geom_vline(aes(xintercept=0),   \n               color=\"red\", linetype=\"dashed\", size=1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nAnalysis:\nThe reason why abline is set to 0 is because it must fall between [-1, 1].\nNegative correlation is -1, No correlation is 0, Positive correlation is 1\nThere is a positive correlation based on the result of the histogram for Moran’s I Statistics\n\n\n\nVisualising Geary’s C test\n\nComputing Spatial Autocorrelation: Geary’s C\nWe will perform Geary’s C statistical test with geary.test() of the spdep package.\n\ngeary.test(hunan$GDPPC, list=rs_wm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rs_wm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nBased on the result, we will reject the null hypothesis as the p-value is less than 0.05. In fact as the p-value is less than 0.01, we can consider that as highly significant.\nTherefore, we can conclude that the GDPPC is not randomly distributed based on Geary’s C statistics\n\n\nComputing Spatial Autocorrelation: Geary’s C with Monte Carlo simulation\nIn order to further confirm that the null hypothesis is false, we could use Monte Carlo simulation to predict potential outcomes of the event by using geary.mc() function of the spdep package. We will use 1000 simulations for this test\n\nset.seed(908)\n\nbpermG = geary.mc(hunan$GDPPC, listw = rs_wm_q, nsim=999)\n\nbpermG\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rs_wm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nBased on the result, we will reject the null hypothesis as the p-value is less than 0.05. In fact as the p-value is less than 0.01, we can consider that as highly significant even when the statistics is repeated 1000 times.\nTherefore, we can conclude that the GDPPC is not randomly distributed based on Geary’s C statistics with Monte Carlo simulation\n\n\nVisualising Monte Carlo Geary’s C\n\nmean(bpermG$res[1:999]) #compute mean\n\n[1] 1.002273\n\nvar(bpermG$res[1:999]) #compute variance\n\n[1] 0.007094831\n\nsd(bpermG$res[1:999]) #compute std dev.\n\n[1] 0.08423082\n\nsummary(bpermG$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7135  0.9477  1.0010  1.0023  1.0577  1.2441 \n\n\nBuilding the histogram\n\nhist(bpermG$res, freq=TRUE, breaks=20, xlab = \"Simulated Geary c\")\nabline (v=1, col=\"blue\")\n\n\n\n\nUsing ggplot, we can reproduce the same graph, however we need to convert the result into a data frame first\n\ndf_G = data.frame(bpermG$res) #convert to data frame\n\nggplot(df_G, aes(bpermG$res)) + #aes = column name\n  geom_histogram(bins=20, \n                 color=\"White\", \n                 fill=\"lightblue\") +\n  labs(x = \"Simulated Geary's C\",\n       y = \"Frequency\") +\n  geom_vline(aes(xintercept=1),   \n               color=\"red\", linetype=\"dashed\", size=1)\n\n\n\n\nAnalysis:\nThe reason why abline is set to 1 is because it must fall between [0, 2].\nNegative correlation is 2, No correlation is 1, Positive correlation is 0, notice that it is essentially the opposite from Moran’s I\nIn Moran I the smaller the number, indicates negative correlation (small -> -ve), in contrast in Geary’s C the smaller the number indicates positive correlation (small -> +ve)\nThere is a positive correlation based on the result of the histogram for Geary’s C statistics"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on Ex3.html#spatial-correlogram",
    "href": "Hands-on_Ex3/Hands-on Ex3.html#spatial-correlogram",
    "title": "Hands On Exercise 2.1 - Global and Local Measures of Spatial Autocorrelation",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nExamining spatial autocorrelation patterns in the data or model residuals is made simple with spatial correlograms.\nThey are graphs of some measure of autocorrelation (Moran’s I or Geary’s C) against distance and they demonstrate how correlated pairs of spatial observations are as one increase the distance (lag) between them.\n\nComputing Moran’s I correlogram\nWe use sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I\nThey are graphs of some measure of autocorrelation (Moran’s I or Geary’s c) against distance and they demonstrate how correlated pairs of spatial observations are as one increase the distance (lag) between them.\nAlthough correlograms are not as fundamental as variograms, which is a fundamental idea in geostatistics, they are nevertheless a very valuable tool for exploratory and descriptive work. They offer deeper insights than variograms do for this purpose.\n\n\nComputing Moran’s I correlogram\nWe use sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I\nPlot() is used to draw the output\n\nMI_Corr = sp.correlogram(wm_q, hunan$GDPPC, order = 6, method = \"I\", style = \"W\")\n\nplot(MI_Corr)\n\n\n\n\nPlotting the output might not allow us to provide complete interpretation, this is because not all autocorrelation values are statistically significant. Hence we should analyze the report by printing out the result\n\nprint(MI_Corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe p value is < 0.05 and hence is statically significant except for the 4th neighbour with p value at 0.226.\nWe can tell that GDPPC is positively correlated for counties up to a distance of 3 neighbours, and negatively correlated from the 5th neighbour onwards.\nAs the 4th degree neighbour is not statistically significant, we will not reject the null hypothesis of it being random.\n\n\nComputing Geary’s C correlogram\nWe use sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C\n\nGC_Corr = sp.correlogram(wm_q, hunan$GDPPC, order = 6, method = \"C\", style = \"W\")\n\nplot(GC_Corr)\n\n\n\n\nPlotting the output might not allow us to provide complete interpretation, this is because not all autocorrelation values are statistically significant. Hence we should analyze the report by printing out the result\n\nprint(GC_Corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn this case, it is only statistically significant for the 1st, 2nd and 5th degree neighbour for GDPPC to be correlated by distance. The rest of the neighbours are not and appears to be random for the Geary’s C method."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on Ex3.html#cluster-and-outlier-analysis",
    "href": "Hands-on_Ex3/Hands-on Ex3.html#cluster-and-outlier-analysis",
    "title": "Hands On Exercise 2.1 - Global and Local Measures of Spatial Autocorrelation",
    "section": "Cluster and Outlier Analysis",
    "text": "Cluster and Outlier Analysis\nStatistics called Local Indicators of Spatial Association, or LISA, assess whether clusters exist in the spatial arrangement of a given variable.\nLocal clusters in the rates, for example, indicate that some census tracts in a given city have greater or lower rates than would be predicted by chance alone; that is, the values observed are higher or lower than those of a random distribution in space.\nWe will use relevant Local Indicators for Spatial Association (LISA), particularly local Moran, in this section to identify clusters and/or outliers in the GDP per capita 2012 figures for Hunan Province.\n\nComputing local Moran’s I\nThe localmoran() function of spdep will be used to calculate local Moran’s I. Given a collection of l_i values, z_i values and a listw object with neighbour weighting details for the polygon associated with the z_i values.\n\nfips = order(hunan$County)\nlocalMI = localmoran(hunan$GDPPC, rs_wm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation (mean) of local Moran statistic under the randomization hypothesis\nVar.Ii: the variance of local Moran statistic under the randomization hypothesis\nZ.Ii: the standard deviation of local Moran statistic\nPr: the p-value of local Moran statistic where it investigate\n\nWe can print the local Moran’s matrix by printCoefmat\n\nprintCoefmat(data.frame(localMI[fips,], \n                        row.names=hunan$County[fips]), \n                        check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\nMapping the local Moran’s I\nBefore mapping the local Moran’s I map, we need to append the local Moran’s I data frame (localMI) onto the Hunan’s spatial polygon data frame by using cbind()\n\nhunan.localMI = cbind(hunan, localMI) %>% #pipe\n                rename(Pr.Ii = Pr.z....E.Ii..)\n\nAfter creating the the new data frame hunan.localMI, we can use the tmap package to plot the local Moran’s I values\n\ntm_shape(hunan.localMI) + \n  tm_fill(col=\"Ii\", #note that actual value is Ii\n          style=\"pretty\", palette = \"PuRd\", title = \"Local Moran's I Statistics\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping local Moran’s I p-values\nThe choropleth map shows that there is evidence for both positive & negative li values. However, we need to consider the p-values for each of these values to determine if they are statistically significant\nBy using breaks and fixed style, we can determine which are the areas that are statistically significant\n\ntm_shape(hunan.localMI) + \n  tm_fill(col=\"Pr.Ii\", #note that p value is Pr.Ii\n          breaks=c(-Inf, 0.001, 0.01, 0.05, Inf),\n          style=\"fixed\",\n          palette = \"-Greens\", title = \"Local Moran's I p values\") +   tm_borders(alpha = 0.5)\n\n\n\n\nIt is recommended to plot the local Moran’s I values map and its associated p-values map side by side for effective interpretation, we can use tmap_arrange() to accomplish that.\n\nlocalMI.map = tm_shape(hunan.localMI) + \n  tm_fill(col=\"Ii\", #note that actual value is li\n          style=\"pretty\", palette = \"PuRd\", title = \"Local Moran's I Statistics\") + \n  tm_borders(alpha = 0.5)\n\n\npvalue.map = tm_shape(hunan.localMI) + \n  tm_fill(col=\"Pr.Ii\", #note that p value is Pr.li\n          breaks=c(-Inf, 0.001, 0.01, 0.05, Inf),\n          style=\"fixed\",\n          palette = \"-Greens\", title = \"Local Moran's I p values\") +   tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\n\n\n\n\nThe Null Hypothesis of Local Moran’s I Statistics\nThe null hypothesis of Local Moran’s I statistics is that there is no correlation between the value at one site and the values at other locations close by. (Long, n.d.)\n\n\nAnalysis of Results of Local Moran’s I Statistics - Dissimilar Features (< 0)\nThe figure below shows the various clusters boxed up that are considered outliers as their I value is less than zero.\nAfter superimposing it with the p value map, we can infer that\n\nOnly 2 areas are statistically significant (labelled by sig), which we can reject the null hypothesis to conclude that there is indeed a correlation in these 2 areas that their neighbouring features having dissimilar characteristics.\nAll other regions that does not have a sig label, the null hypothesis is accepted and they have a negative local Moran I value purely due to chance.\n\n\n\n\nAnalysis of Results of Local Moran’s I Statistics - Similar Features (>= 0)\nThe figure below shows the various clusters boxed up with similarly high or low attribute values as the local Moran I Statistics is more than or equal to zero.\nAfter superimposing it with the p value map, we can infer that\n\nCluster A is the most statistically significant, the area GDPPC is highly influence by its neighbours as we reject the null hypothesis. Only 2 areas has very different features as explained in the previous section. The 2 dissimilar area however, seems to suggest that they are outskirt of cluster A.\nIn Cluster B, only 4 sites are influence by one another, however the influence is weak as the I statistics is between zero and one\nIn cluster C, it looks like only its first degree neighbour has some influence over the GDPPC of the area in the statistically significant lone area\nIn all other regions. the null hypothesis is accepted and they have a positive local Moran I value purely due to chance.\n\n\nThe relevant sites are color coded on the LISA Cluster Map according to the type of spatial autocorrelation.\nThe Moran scatterplot must first be drawn before we can create the LISA cluster map.\n\n\n\nPlotting Moran Scatterplot\n\nA helpful visual tool for exploratory analysis is the Moran scatter plot, which helps one to judge how similar an observed value is to its nearby observations.\nThe y axis, also referred to as the response axis , is dependent on the values of the observations.\nBased on the weighted average or spatial lag of the corresponding observation on the X axis, the Y axis is constructed.\n\n\nnci = moran.plot(hunan$GDPPC, rs_wm_q, \n                 labels=as.character(hunan$County),\n                 xlab = \"GDPPC 2012\",\n                 ylab=\"Spatially lag GDPPC 2012\",\n                 xlim=c(0, 90000), ylim=c(0,60000), pch=5\n)\n\n\n\n\nThe plot is split into 4 quadrants, below is an example of what each quadrant represents.\n\nThe global Moran’s I is estimated from the slope of the regression line. The relative density of the dots in the correlation quadrants shows how association between high and/or low values determines the overall measure of spatial relationship. (Figure 5, Gomez, et al, 2011)\n\nAnalysis\n\nFrom the resulting plot, we can see that majority of the points are positively correlated but are below the average.\nThe areas that are above the average in the high-high quadrant are likely represented by purple and dark red spots on the local Moran’s I map in Cluster A.\nZiXing and LengShuiJiang are likely the 2 areas with dissimilar features in cluster A as previously explained.\n\n\n\n\nPreparing LISA map classes\n\nCreate the quadrants\n\nquadrant = vector(mode=\"numeric\",length=nrow(localMI))\n\nCenter the variable of interest around its mean\n\nDV = hunan$GDPPC - mean(hunan$GDPPC)\n\nCenter the local Moran’s I value around the mean\n\n#local moran\nC_MI = (localMI[,1] - mean(localMI[,1]))\n\nSetup the statistically significant levels for the local Moran\n\nsignif = 0.05\n\nDefine the quadrants levels\n\n#C_MI = Local Moran I\nquadrant[DV > 0 & C_MI > 0] = 4 #C_MI > 0 -> cluster, DV > 0 high-high pattern\nquadrant[DV < 0 & C_MI < 0] = 2 #C_MI < 0 -> outlier,  DV < 0 Low High\nquadrant[DV < 0 & C_MI > 0] = 1 #C_MI > 0 -> cluster, DV < 0 low-low pattern\nquadrant[DV > 0 & C_MI < 0] = 3 #C_MI < 0 -> outlier,  DV < 0 High Low\n\nPlace non significant Moran into category 0\n\nquadrant[localMI[,5]>signif] = 0\n\nPlotting the LISA Map\n\nhunan.localMI$quadrant <- quadrant\ncolors = c(\"white\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters = c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) + \n  tm_fill(col=\"quadrant\", style=\"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n          tm_view(set.zoom.limits = c(11,17)) +\n          tm_borders(alpha=0.5)\n\n\n\n\n\nFor effective interpretation, it is better to plot both the LISA map and its GDPPC map next to each other.\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant <- quadrant\ncolors = c(\"white\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters = c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAMap = tm_shape(hunan.localMI) + \n  tm_fill(col=\"quadrant\", style=\"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n          tm_borders(alpha=0.5)\n\n#tmap_arrange(localMI.map, LISAMap, pvalue.map, asp=1, ncol=3)\ntmap_arrange(gdppc, LISAMap, asp=1, ncol=2)\n\n\n\n\n\nAnalysis\n\nComparing the GDPPC and LISA maps, it tallies with the analysis in the Local Moran’s section that the dissimilar areas have low GDPPC, while similar regions have high GDPPC in cluster A\nThere are also 2 low high areas in cluster B, these are outliers that neighbours affects its GDPPC. They are likely to be ZhuZhou and XiangTan in the Moran Scatter plot\nIn cluster C, the significant area is likely PingJiang as an outlier in the Moran Scatter plot, where most neighbouring counties have low GDPPC, while it has a GDPPC of between 20k to 40k. However, in the LISA plot, it is insignificant.\nThe small area at the center of the map, although it has high GDPPC, but only has 3 neighbours, as the number of neighbours is small, it has been considered to be statistically insignificant in hte LISA Map\n\nFor reference, the figure below was previously discussed in the Local Moran’s Section.\n\n\n\n\nHot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\nA hot spot is a location where high values cluster together\nA cold spot is a location place where low values cluster together\n• Moran’s I and Geary’s C cannot distinguish them\n• They only indicate clustering\n• Cannot tell if these are hot spots, cold spots, or both\n\n\nGetis and Ord’s G-Statistics\nThe G statistic distinguishes between hot spots and cold spots. It identifies spatial concentrations.\n\nG is relatively large if high values cluster together\nG is relatively low if low values cluster together\n\nThe General G statistic is interpreted relative to its mean (or expected) value. The value for which there is no spatial association\n\nG > expected value -> potential “hot spots”\nG < expected value -> potential “cold spots”\n\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\nDeriving distance-based weight matrix\nWe must first specify a new set of neighbours. While the spatial autocorrelation took into account units that shared borders, in Getis-Ord, neighbours are determined based on distance. There are 2 types of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\nThe reason why G statistics requires centroids is because it is based on point pattern analysis logic, which is very different from LISA or Local Moran’s I that compares local-global correlation.\n\nlongitude = map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind() to put longitude and latitude into the same object.\n\ncoord = cbind(longitude, latitude)\n\n\n\nDetermine the cut-off distance\n\nFind the lower and upper bounds\n\nUsing the k nearest neighbour (knn) algorithm, we can return a matrix with indices of points that belongs to the set of k nearest neighbours of each others by using knearneigh() of spdep\nConvert the knn objects into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb()\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the return objects by using unlist()\n\nk1 = knn2nb(knearneigh(coord)) #returns a list of nb objects from the result of k nearest neighbours matrix, Step 1 & 2\nk1dist = unlist(nbdists(k1, coord, longlat = TRUE)) #return the length of neighbour relationship edges and remove the list structures, Step 3 & 4\nsummary(k1dist)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nFrom the result, the largest first nearest neighbour is 61.79km, hence by using this as the upper bound, we can be certain that all units will have at least 1 neighbour\ndnearneigh will be used to compute the distance weight matrix\n\nwm_d62 = dnearneigh(coord, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext nb2listw() is used to convert the nb object into spatial weights objects\n\nwm62_lw = nb2listw(wm_d62, style=\"B\")\nsummary(wm62_lw) \n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe fixed distance weight matrix has the property that locations with higher densities of habitation (often urban areas) tend to have more neighbours, whereas areas with lower densities (typically rural areas) tend to have fewer neighbours.\nBy enforcing symmetry or accepting asymmetric neighbours, as shown in the code below, it is possible to control the number of neighbours of each region using the knn algorithm.\n\nknn8 = knn2nb(knearneigh(coord, k=8))\n\nNext nb2listw() is used to convert the nb object into spatial weights objects\n\nknn_lw = nb2listw(knn8, style = \"B\")\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on Ex3.html#computing-gi-statistics",
    "href": "Hands-on_Ex3/Hands-on Ex3.html#computing-gi-statistics",
    "title": "Hands On Exercise 2.1 - Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Gi statistics",
    "text": "Computing Gi statistics\n\nGi statistics using fixed distance (G Statistics)\n\nfips = order(hunan$County)\ngi.fixed = localG(hunan$GDPPC, wm62_lw, return_internals = TRUE)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw, return_internals = TRUE)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the cbind()\n\nhunan.gi = cbind(hunan, as.matrix(gi.fixed)) %>% #pipe\n          rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThe code above performs 3tasks.\n\nFirst, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix().\ncbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi.\n\nthe field name of the gi values is renamed to gstat_fixed by using rename().\n\n\nMapping Gi values with fixed distance weights\nWe plot the map and the gimap side by side for analysis\n\nGimap_fixed = tm_shape(hunan.gi) +\n          tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap_fixed, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nAnalysis\nComparing with Local Moran’s map that was discussed below, we can see that the dissimilar areas were classified as a hot spot.\nConversely, the spatial outliers in Cluster B and C were groups as cold spots in the G Statistics Map.\n\nThe reason for this phenomenon is that the G statistics does not take into account outliers as it does not consider spatial correlation. It only take into account hot spots & cold spots.\nFrom the result, we can infer that the GDPPC of the hot spot regions has high GDPPC, while the cold spot regions has low GDPPC.\n\n\n\nMapping Gi values with adaptive distance weights (G* Statistics)\nThe code below is used to compute the Gi values for GDPPC 2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips = order(hunan$County)\ngi.adaptive = localG(hunan$GDPPC, knn_lw, return_internals = TRUE)\ngi.adaptive\n\n [1]  0.274428799  0.300225037  0.030447697 -0.009771412 -0.033921570\n [6] -0.154780126  4.034649782  2.057586016  4.378892586  1.479129376\n[11]  0.761743842 -0.648205275 -0.773677838  0.589236922  1.040407601\n[16]  0.368526533 -0.604240867 -0.241840937  0.031714037 -0.110547691\n[21]  0.761314356  1.175580259 -0.884714136 -0.860993329 -1.643096490\n[26] -1.290687016 -1.422253022 -0.675281508 -1.719511109 -1.210266137\n[31] -1.300914263 -1.599085669 -1.298761870 -1.836622587  1.637619520\n[36] -0.721435309 -1.958848641 -1.665195897 -1.868014845 -1.183536130\n[41] -0.169560764 -2.084882362 -2.181780084 -2.081025645 -0.499000625\n[46]  2.194733590  2.495469794 -1.695557884 -0.745540634 -1.193763093\n[51] -1.821073681 -1.894085866 -1.570969008 -1.055766446 -1.299966539\n[56] -0.201823610  0.498063690  0.581955247 -0.876827566 -0.955484907\n[61] -0.723004897 -0.790993867 -0.183585082  1.129758266  2.271097895\n[66]  3.047193741  4.995149600  4.022126163 -0.313165513  0.384924896\n[71]  3.018245449  0.561045961  0.210102660  4.365942776 -1.210175378\n[76]  2.391729501 -1.188720061  3.068344267 -0.600223372  1.046676007\n[81] -1.427632954 -0.156355526  1.176546366  3.726230897 -0.327758027\n[86]  2.972571047 -1.009008013 -0.989393051\nattr(,\"internals\")\n              Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.09720587 0.09195402 0.0003662397  0.274428799   7.837551e-01\n [2,] 0.09769063 0.09195402 0.0003651040  0.300225037   7.640055e-01\n [3,] 0.09253816 0.09195402 0.0003680612  0.030447697   9.757100e-01\n [4,] 0.09176695 0.09195402 0.0003665281 -0.009771412   9.922037e-01\n [5,] 0.09130429 0.09195402 0.0003668767 -0.033921570   9.729397e-01\n [6,] 0.08898762 0.09195402 0.0003673079 -0.154780126   8.769947e-01\n [7,] 0.16751891 0.09195402 0.0003507748  4.034649782   5.468380e-05\n [8,] 0.13054918 0.09195402 0.0003518436  2.057586016   3.962989e-02\n [9,] 0.17277103 0.09195402 0.0003406253  4.378892586   1.192839e-05\n[10,] 0.12001759 0.09195402 0.0003599760  1.479129376   1.391057e-01\n[11,] 0.10633361 0.09195402 0.0003563487  0.761743842   4.462129e-01\n[12,] 0.07951853 0.09195402 0.0003680448 -0.648205275   5.168522e-01\n[13,] 0.07714548 0.09195402 0.0003663568 -0.773677838   4.391213e-01\n[14,] 0.10311529 0.09195402 0.0003587953  0.589236922   5.557024e-01\n[15,] 0.11178796 0.09195402 0.0003634216  1.040407601   2.981506e-01\n[16,] 0.09902122 0.09195402 0.0003677535  0.368526533   7.124807e-01\n[17,] 0.08068910 0.09195402 0.0003475655 -0.604240867   5.456835e-01\n[18,] 0.08732412 0.09195402 0.0003665092 -0.241840937   8.089034e-01\n[19,] 0.09256190 0.09195402 0.0003673900  0.031714037   9.747001e-01\n[20,] 0.08984049 0.09195402 0.0003655276 -0.110547691   9.119750e-01\n[21,] 0.10653391 0.09195402 0.0003667585  0.761314356   4.464693e-01\n[22,] 0.11447605 0.09195402 0.0003670374  1.175580259   2.397626e-01\n[23,] 0.07508563 0.09195402 0.0003635312 -0.884714136   3.763108e-01\n[24,] 0.07555112 0.09195402 0.0003629457 -0.860993329   3.892417e-01\n[25,] 0.06043622 0.09195402 0.0003679474 -1.643096490   1.003630e-01\n[26,] 0.06742593 0.09195402 0.0003611483 -1.290687016   1.968122e-01\n[27,] 0.06478946 0.09195402 0.0003647974 -1.422253022   1.549528e-01\n[28,] 0.07912867 0.09195402 0.0003607191 -0.675281508   4.994969e-01\n[29,] 0.05932898 0.09195402 0.0003599915 -1.719511109   8.552135e-02\n[30,] 0.06893033 0.09195402 0.0003618998 -1.210266137   2.261768e-01\n[31,] 0.06724327 0.09195402 0.0003608067 -1.300914263   1.932878e-01\n[32,] 0.06134370 0.09195402 0.0003664310 -1.599085669   1.098016e-01\n[33,] 0.06714525 0.09195402 0.0003648812 -1.298761870   1.940257e-01\n[34,] 0.05762358 0.09195402 0.0003493969 -1.836622587   6.626563e-02\n[35,] 0.12317148 0.09195402 0.0003633868  1.637619520   1.015011e-01\n[36,] 0.07825698 0.09195402 0.0003604615 -0.721435309   4.706417e-01\n[37,] 0.05490035 0.09195402 0.0003578169 -1.958848641   5.013052e-02\n[38,] 0.06013762 0.09195402 0.0003650661 -1.665195897   9.587368e-02\n[39,] 0.05649408 0.09195402 0.0003603425 -1.868014845   6.176000e-02\n[40,] 0.06958160 0.09195402 0.0003573248 -1.183536130   2.365967e-01\n[41,] 0.08870667 0.09195402 0.0003667818 -0.169560764   8.653556e-01\n[42,] 0.05226797 0.09195402 0.0003623370 -2.084882362   3.707998e-02\n[43,] 0.05058836 0.09195402 0.0003594662 -2.181780084   2.912577e-02\n[44,] 0.05256094 0.09195402 0.0003583316 -2.081025645   3.743156e-02\n[45,] 0.08249954 0.09195402 0.0003589829 -0.499000625   6.177789e-01\n[46,] 0.13351191 0.09195402 0.0003585448  2.194733590   2.818271e-02\n[47,] 0.13980943 0.09195402 0.0003677540  2.495469794   1.257905e-02\n[48,] 0.05972453 0.09195402 0.0003613115 -1.695557884   8.996964e-02\n[49,] 0.07779955 0.09195402 0.0003604495 -0.745540634   4.559450e-01\n[50,] 0.06933428 0.09195402 0.0003590369 -1.193763093   2.325707e-01\n[51,] 0.05717238 0.09195402 0.0003647919 -1.821073681   6.859566e-02\n[52,] 0.05561872 0.09195402 0.0003680088 -1.894085866   5.821361e-02\n[53,] 0.06225124 0.09195402 0.0003574860 -1.570969008   1.161898e-01\n[54,] 0.07183294 0.09195402 0.0003632178 -1.055766446   2.910749e-01\n[55,] 0.06738016 0.09195402 0.0003573408 -1.299966539   1.936124e-01\n[56,] 0.08811771 0.09195402 0.0003613143 -0.201823610   8.400546e-01\n[57,] 0.10147288 0.09195402 0.0003652580  0.498063690   6.184392e-01\n[58,] 0.10310390 0.09195402 0.0003670801  0.581955247   5.605968e-01\n[59,] 0.07526754 0.09195402 0.0003621606 -0.876827566   3.805803e-01\n[60,] 0.07370784 0.09195402 0.0003646671 -0.955484907   3.393325e-01\n[61,] 0.07823737 0.09195402 0.0003599264 -0.723004897   4.696769e-01\n[62,] 0.07683091 0.09195402 0.0003655412 -0.790993867   4.289476e-01\n[63,] 0.08846487 0.09195402 0.0003612141 -0.183585082   8.543390e-01\n[64,] 0.11362359 0.09195402 0.0003678997  1.129758266   2.585781e-01\n[65,] 0.13552322 0.09195402 0.0003680335  2.271097895   2.314105e-02\n[66,] 0.15029172 0.09195402 0.0003665206  3.047193741   2.309888e-03\n[67,] 0.18713548 0.09195402 0.0003630845  4.995149600   5.879018e-07\n[68,] 0.16912010 0.09195402 0.0003680793  4.022126163   5.767515e-05\n[69,] 0.08597972 0.09195402 0.0003639373 -0.313165513   7.541549e-01\n[70,] 0.09930460 0.09195402 0.0003646621  0.384924896   7.002931e-01\n[71,] 0.14976364 0.09195402 0.0003668522  3.018245449   2.542429e-03\n[72,] 0.10267460 0.09195402 0.0003651229  0.561045961   5.747662e-01\n[73,] 0.09598415 0.09195402 0.0003679379  0.210102660   8.335875e-01\n[74,] 0.17564058 0.09195402 0.0003674137  4.365942776   1.265756e-05\n[75,] 0.06894940 0.09195402 0.0003613546 -1.210175378   2.262116e-01\n[76,] 0.13777971 0.09195402 0.0003671080  2.391729501   1.676920e-02\n[77,] 0.06924543 0.09195402 0.0003649397 -1.188720061   2.345498e-01\n[78,] 0.15052389 0.09195402 0.0003643681  3.068344267   2.152485e-03\n[79,] 0.08060684 0.09195402 0.0003573967 -0.600223372   5.483574e-01\n[80,] 0.11191592 0.09195402 0.0003637301  1.046676007   2.952490e-01\n[81,] 0.06473996 0.09195402 0.0003633737 -1.427632954   1.533975e-01\n[82,] 0.08896972 0.09195402 0.0003643008 -0.156355526   8.757528e-01\n[83,] 0.11452640 0.09195402 0.0003680752  1.176546366   2.393766e-01\n[84,] 0.15719339 0.09195402 0.0003065349  3.726230897   1.943644e-04\n[85,] 0.08568420 0.09195402 0.0003659344 -0.327758027   7.430946e-01\n[86,] 0.14892272 0.09195402 0.0003672891  2.972571047   2.953169e-03\n[87,] 0.07271488 0.09195402 0.0003635650 -1.009008013   3.129708e-01\n[88,] 0.07310269 0.09195402 0.0003630331 -0.989393051   3.224709e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = knn_lw, return_internals = TRUE)\nattr(,\"class\")\n[1] \"localG\"\n\nhunan.gi = cbind(hunan, as.matrix(gi.adaptive)) %>% #pipe\n            rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\nWe plot the map and the gimap side by side for analysis\n\nGimap_adaptive = tm_shape(hunan.gi) +\n          tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap_adaptive, asp=1, ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\ntmap_arrange(Gimap_fixed, Gimap_adaptive, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nAnalysis\nThe G Statistics using fixed weight is simply the spatial lag, while the G* statistics using adaptive weights is the weighted average of neighbour value at region i\nThis allow us to find how much weight one need to give the location relative to its neighbours.\nWith the G* statistics, we could tell that the hotspot has shrunk and became more intense, as relative weights were assigned, this method is more robust as compared to the G statistics which uses a consistent weight across its analysis.\nFrom the result, we can infer that the GDPPC of the hot spot regions has high GDPPC, while the cold spot regions has low GDPPC.\nBased on this exercise, the Local Moran Statistics, LISA Map and G Statistical test has gave consistent results with regards to Cluster A. Thus, we can draw the conclusion that Cluster A is likely to be an urban area with higher degree of economic activity than the rest of Hunan, which leads to a higher GDPPC."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on Ex3.html#reference",
    "href": "Hands-on_Ex3/Hands-on Ex3.html#reference",
    "title": "Hands On Exercise 2.1 - Global and Local Measures of Spatial Autocorrelation",
    "section": "Reference",
    "text": "Reference\nAnselin L. (2020) Local Spatial Autocorrelation (1) LISA and Local Moran https://geodacenter.github.io/workbook/6a_local_auto/lab6a.html#local-moran\nArcGIS Pro 3.0, How Spatial Autocorrelation (Global Moran’s I) works\nhttps://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/h-how-spatial-autocorrelation-moran-s-i-spatial-st.htm\nGomez, Cristina & White, Joanne & Wulder, Michael. (2011). Characterizing the state and processes of change in a dynamic forest environment using hierarchical spatio-temporal segmentation. Remote Sensing of Environment. 115. 1665-1679. 10.1016/j.rse.2011.02.025.\nLong, A (n.d.), Local Moran\nhttp://ceadserv1.nku.edu/longa//geomed/stats/localmoran/localmoran.html"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html",
    "href": "In-Class_Ex1/In-class_Ex1.html",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "",
    "text": "In Class Exercise 1 - Applications of Spatial Weights, this page describes how to apply spatial weights for geospatial analysis"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#getting-started",
    "href": "In-Class_Ex1/In-class_Ex1.html#getting-started",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below install & load sf, spdep, tmap & tidyverse packages into the R env\n\npacman::p_load(sf,tidyverse,spdep, tmap)\n\n\nImporting Hunan Geospatial sf\n\nhunan_sf = st_read(dsn=\"data/geospatial\", layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\Allanckw\\ISSS624\\In-Class_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nLoading Hunan 2012 Aspatial File in CSV\n\nhunan_GDP = read_csv(\"data/aspatial/hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#joining-attribute-data-to-the-simple-feature-files",
    "href": "In-Class_Ex1/In-class_Ex1.html#joining-attribute-data-to-the-simple-feature-files",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Joining attribute data to the simple feature files",
    "text": "Joining attribute data to the simple feature files\nNext, left_join() of dplyr is used to join the geographical data and attribute table\n\nhunan = left_join(hunan_sf, hunan_GDP)\n\nJoining, by = \"County\""
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#visualizing-regional-development-indicator",
    "href": "In-Class_Ex1/In-class_Ex1.html#visualizing-regional-development-indicator",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Visualizing Regional Development Indicator",
    "text": "Visualizing Regional Development Indicator\nUsing the tmap package, we can visualize the distribution of GDPPC 2012\n\nbasemap = tm_shape(hunan) + \n          tm_polygons()\n\ngdppc = tm_shape(hunan) +\n        tm_polygons(\"GDPPC\")\n\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#computing-contiguity-spatial-weights",
    "href": "In-Class_Ex1/In-class_Ex1.html#computing-contiguity-spatial-weights",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nIn this section, the poly2nb() function of the spdep package is used to compute contiguity weight matrices for the study area\n\nThe function builds a neighbour list based on regions with contiguous boundaries, the default of the algorithm uses Queens case, unless explicitly set to false\n\n\nwm_q = poly2nb(hunan)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\nwm_r = poly2nb(hunan, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nFrom the results, there are 88 regions in Hunan,\nUsing the Queen’s method, 85 of them has 11 neighbours, while only 2 of them has 1 neighbour\nUsing the Rook’s method 85 of them has 10 neighbours, while only 2 of them has 1 neighbour\nTo see neighbours for polygons in the objects, we could reference them like the below for the first polygon:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nFrom the result, we know Polygon 1 has 5 neighbours, the numbers represents the polygon IDs of the respective neighbours stored in the hunan SpatialPolygonsDataFrame class\nWe can retrieve the county name of polygon ID 1 by using\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nTo reveal the names of the 5 neighbours, we can use\n\nhunan$County[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nTo reveal the GDPPC of these 5 counties, we can use\n\nnb1 = wm_q[[1]] \nnb1 = hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe result displays the 5 nearest neighbours based on Queen’s method\nThe complete weight matrix can be displayed by using the str() function\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#visualizing-contiguity-weights",
    "href": "In-Class_Ex1/In-class_Ex1.html#visualizing-contiguity-weights",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Visualizing contiguity weights",
    "text": "Visualizing contiguity weights\nIn a connectivity graph, each point’s neighbouring points are represented by a line. As the exercise is focused on  polygons, points needs to be created before we can build connectivity graphs. Polygon centroids will be the mechanism used for this purpose. \n\nGetting Latitude and Longitude of Polygon Centroids\nBefore we can create the connectivity graph, we must assign points to each polygon.  For this to function, we need the coordinates in a separate data frame. We’ll utilize a mapping function to accomplish this. The mapping function creates a vector of identical length by applying a specified function to each element of a vector. We will use the geometry column of us.bound as our input vector. \nst_centroid from the sf package & map_dblfrom the purrr package will be used to accomplish this. We can map the st_centroid function over the geometry column us.bounds to obtain our required values.\n\nThe longitude is the first variable in each centroid, this enables us to obtain only the longitude.\nThe latitude is the second variable in each centroid, this enables us to obtain only the latitude\nUsing the double bracket notation [[]] and the index, we can access the latitude & longitude values.\n\nlongitude = map_dbl(hunan$geometry, ~st_centroid(.x)[[1]]) #longitude index 1\nlatitude = map_dbl(hunan$geometry, ~st_centroid(.x)[[2]]) #latitude index 2\n\nAfter getting the longitude and latitudes, we can form the coordinates object named coord using cbind\nUsing the head function, we can inspect the elements of coord to verify if they are correctly formatted\n\ncoord = cbind(longitude, latitude)\nhead(coord)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\nPlotting Queen contiguity based neighbours map\nWe can now plot the contiguity graph with our coord object\n\nUsing Queen’s method with wm_q\n\nplot(hunan$geometry, border=\"lightblue\")\nplot(wm_q, coord, pch = 19, cex = 0.6, add = TRUE, col= \"black\")\n\n\n\n\n\n\nUsing Rook’s Method with wm_r\n\nplot(hunan$geometry, border=\"lightblue\")\nplot(wm_r, coord, pch = 19, cex = 0.6, add = TRUE, col= \"black\")\n\n\n\n\n\n\nPlotting both Rook’s & Queen’s method\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightblue\")\nplot(wm_r, coord, pch = 19, cex = 0.6, add = TRUE, col= \"black\")\nplot(hunan$geometry, border=\"lightblue\")\nplot(wm_q, coord, pch = 19, cex = 0.6, add = TRUE, col= \"black\")"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#computing-distance-based-neighbours",
    "href": "In-Class_Ex1/In-class_Ex1.html#computing-distance-based-neighbours",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Computing distance based neighbours",
    "text": "Computing distance based neighbours\nWith the use of Neighbourhood contiguity by distance - dnearneigh() of spdep package, we can determine the distance based weight matrix.\nThe function looks for neighbours of regions points by Euclidean distance between the lower (>=) and upper (<=) bound or with the parameter longlat = True by great circle distance in km\n\nFind the lower and upper bounds\n\nUsing the k nearest neighbour (knn) algorithm, we can return a matrix with indices of points that belongs to the set of k nearest neighbours of each others by using knearneigh() of spdep\nConvert the knn objects into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb()\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the return objects by using unlist()\n\n\nk1 = knn2nb(knearneigh(coord)) #returns a list of nb objects from the result of k nearest neighbours matrix, Step 1 & 2\nk1dist = unlist(nbdists(k1, coord, longlat = TRUE)) #return the length of neighbour relationship edges and remove the list structures, Step 3 & 4\nsummary(k1dist)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nFrom the result, the largest first nearest neighbour is 61.79km, hence by using this as the upper bound, we can be certain that all units will have at least 1 neighbour\n\n\nFinding the fixed distanced weight matrix\ndnearneigh will be used to compute the distance weight matrix\n\nwm_d62 = dnearneigh(coord, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThe average number of links denotes the number of non zero links divided by the number of regions. In this case, a region has about on average between 3-4 neighbours\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coord, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\nThe card() function counts the neighboring regions in the neighbours list.\ntable() creates a contingency table of the counts for each combination of factor levels using cross-classifying factors.\n\n\ncardinality = card(wm_d62)\ntable(hunan$County, cardinality) \n\n               cardinality\n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\nn.comp.nb() finds the number of disjoint connected subgraphs in the graph depicted by nb.obj - a spatial neighbours list object using depth first search\n\nn_comp = n.comp.nb(wm_d62)\n\nIt returns\n\nnc: number of disjoint connected subgraphs\ncomp.id: vector with the indices of the disjoint connected subgraphs that the nodes in nb.obj belong to, in this case the distance weight matrix\n\n\nn_comp$nc\n\n[1] 1\n\n#n_comp$comp.id\ntable(n_comp$comp.id)\n\n\n 1 \n88"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#plotting-fixed-distance-weight-matrix",
    "href": "In-Class_Ex1/In-class_Ex1.html#plotting-fixed-distance-weight-matrix",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Plotting fixed distance weight matrix",
    "text": "Plotting fixed distance weight matrix\nWe can plot the distance weight matrix by using the code below.\n\nplot(hunan$geometry, border=\"lightblue\")\nplot(wm_d62, coord, add=TRUE)\nplot(k1, coord, add=TRUE, col=\"red\", length = 0.1)\n\n\n\n\n\nThe black lines show the links of neighbours within the cut-off distance of 62km.\nThe red lines show the links of 1st nearest neighbours\n\nAlternatively, we can plot both of them next to each other with the code below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightblue\")\nplot(wm_d62, coord, add=TRUE)\nplot(hunan$geometry, border=\"lightblue\")\nplot(k1, coord, add=TRUE, col=\"red\", length = 0.1)"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#computing-adaptive-distance-weight-matrix",
    "href": "In-Class_Ex1/In-class_Ex1.html#computing-adaptive-distance-weight-matrix",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Computing adaptive distance weight matrix",
    "text": "Computing adaptive distance weight matrix\nThe fixed distance weight matrix has the property that locations with higher densities of habitation (often urban areas) tend to have more neighbours, whereas areas with lower densities (typically rural areas) tend to have fewer neighbours.\nBy enforcing symmetry or accepting asymmetric neighbours, as shown in the code below, it is possible to control the number of neighbours of each region using the knn algorithm.\n\nknn6 = knn2nb(knearneigh(coord, k=6))\n\nSimilarly, we can display the content of the matrix by using str()\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coord, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\nPlotting distance based neighbours\n\nplot(hunan$geometry, border=\"lightblue\")\nplot(knn6, coord, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#weights-based-on-inverse-distance-methods",
    "href": "In-Class_Ex1/In-class_Ex1.html#weights-based-on-inverse-distance-methods",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Weights based on Inverse distance methods",
    "text": "Weights based on Inverse distance methods\nWe will need to compute the distances between areas using nbdists() of spdep package\n\ndist = nbdists(wm_q, coord, longlat=TRUE)\nids = lapply(dist, function(x) 1/ (x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\nRow standardize Weight Matrix\nThe nb2listw function adds spatial weights for the selected coding scheme to a neighbours list. It’s possible to determine whether a spatial weights object is similar to symmetric and can be transformed in this way to produce real eigenvalues or for Cholesky decomposition.\nThere are a number of Styles to choose from (Bivand, n.d)\n\nB is the basic binary coding,\nW is row standardised (sums over all links to n),\nC is globally standardised (sums over all links to n),\nU is equal to C divided by the number of neighbours (sums over all links to unity),\nS is the variance-stabilizing coding scheme\n\nFor this example, we’ll stick with the style=“W” option for simplicity’s but note that other more robust options are available, notably style=“B”, basic binary coding.\n\nrswm_q = nb2listw(wm_q, style=\"W\", zero.policy=TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nLists of non-neighbours are possible with the zero.policy=TRUE option.\nA zero.policy of FALSE would return an error, however this should be used carefully as the user might not be aware of missing neighbors in their dataset.\nTo view the weight of the first polygon’s 10 neighbour types, we can use the code below\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardized distance weight matrix by using the code below.\n\nrswm_ids <- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#application-of-spatial-weight-matrix",
    "href": "In-Class_Ex1/In-class_Ex1.html#application-of-spatial-weight-matrix",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Application of Spatial Weight Matrix",
    "text": "Application of Spatial Weight Matrix\nIn this section, 4 different spatial lagged variables are discussed, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average,\nspatial window sum.\n\n\n1. Spatial lag with row-standardized weights\nFirst, Compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values. We use lag.listw to compute the Spatial lag of a numeric vector\n\ngdppc.lag = lag.listw(rswm_q, hunan$GDPPC)\ngdppc.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nUsing the code below, we can append the spatially lag GDPPC values to the Hunan sf data frame.\n\nlag.list = list(hunan$County, gdppc.lag) #lag.listw(rswm_q, hunan$GDPPC)\nlag.res = as.data.frame(lag.list)\ncolnames(lag.res) = c(\"County\", \"lag GDPPC\")\nhunan = left_join(hunan, lag.res)\n\nJoining, by = \"County\"\n\nhead(hunan)\n\nSimple feature collection with 6 features and 36 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County    City\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang Changde\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou Changde\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi Changde\n4 Changde 21102      Li      County   3.474325 0.18908121      Li Changde\n5 Changde 21103   Linli      County   2.289506 0.11450357   Linli Changde\n6 Changde 21104  Shimen      County   4.171918 0.37194707  Shimen Changde\n  avg_wage deposite     FAI Gov_Rev Gov_Exp     GDP GDPPC     GIO   Loan  NIPCR\n1    31935   5517.2  3541.0  243.64  1779.5 12482.0 23667  5108.9 2806.9 7693.7\n2    32265   7979.0  8665.0  386.13  2062.4 15788.0 20981 13491.0 4550.0 8269.9\n3    28692   4581.7  4777.0  373.31  1148.4  8706.9 34592 10935.0 2242.0 8169.9\n4    32541  13487.0 16066.0  709.61  2459.5 20322.0 24473 18402.0 6748.0 8377.0\n5    32667    564.1  7781.2  336.86  1538.7 10355.0 25554  8214.0  358.0 8143.1\n6    33261   8334.4 10531.0  548.33  2178.8 16293.0 27137 17795.0 6026.5 6156.0\n   Bed    Emp  EmpR EmpRT Pri_Stu Sec_Stu Household Household_R NOIP Pop_R\n1 1931 336.39 270.5 205.9  19.584  17.819     148.1       135.4   53 346.0\n2 2560 456.78 388.8 246.7  42.097  33.029     240.2       208.7   95 553.2\n3  848 122.78  82.1  61.7   8.723   7.592      81.9        43.7   77  92.4\n4 2038 513.44 426.8 227.1  38.975  33.938     268.5       256.0   96 539.7\n5 1440 307.36 272.2 100.8  23.286  18.943     129.1       157.2   99 246.6\n6 2502 392.05 329.6 193.8  29.245  26.104     190.6       184.7  122 399.2\n    RSCG Pop_T    Agri Service Disp_Inc      RORP    ROREmp lag GDPPC\n1 3957.9 528.3 4524.41   14100    16610 0.6549309 0.8041262  24847.20\n2 4460.5 804.6 6545.35   17727    18925 0.6875466 0.8511756  22724.80\n3 3683.0 251.8 2562.46    7525    19498 0.3669579 0.6686757  24143.25\n4 7110.2 832.5 7562.34   53160    18985 0.6482883 0.8312558  27737.50\n5 3604.9 409.3 3583.91    7031    18604 0.6024921 0.8856065  27270.25\n6 6490.7 600.5 5266.51    6981    19275 0.6647794 0.8407091  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nWe can plot the GDPPC and spatial lag GDPPC for comparison using the code below\n\nlag_gdppc = tm_shape(hunan) +\n        tm_polygons(\"lag GDPPC\")\n\ntmap_arrange(gdppc, lag_gdppc)\n\n\n\n\n\n\n2 Spatial lag as a sum of neighboring values\nAnother way to compute spatial lag as a sum of neigbouring values is by assigning binary weights.\nGoing back to the neighbours list wm_q, we can apply a function that will assign binary weights by using lapply, and use nb2listw to assign the weights, using the glist parameter to explicitly assign these wieghts\n\nb_weights = lapply(wm_q, function(x) 0*x + 1)\nb_weights2 = nb2listw(wm_q, glist = b_weights, style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nAfter the weight have been assigned, we can use lag.listw to calculate the lag variable from our weights and GDPPC\n\nlag_sum = list(hunan$County, lag.listw(b_weights2, hunan$GDPPC))\nlag.res = as.data.frame(lag_sum)\ncolnames(lag.res) = c(\"County\", \"lag_sum GDPPC\")\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nExamining the result of the lag_sum, the first value of lag_sum is 124236, comparing it with the value in gdppc.lag discussed in Spatial lag with row-standardized weights, the first value was 24847.20.\nIt can be observed that a weight of 5 has been multiplied. In our earlier discussion, we know that Anxiang has 5 neighbours. Hence, we can conclude that the spatial lag sum method will multiply the result of Spatial lag with row-standardized weights by the number of neighbours in a region.\nUsing the code below, we can append the spatial lag sum GDPPC values to the Hunan sf data frame.\n\nhunan = left_join(hunan, lag.res)\n\nJoining, by = \"County\"\n\n\nWe can plot the GDPPC and spatial lag GDPPC for comparison using the code below\n\nlag_sum_gdppc = tm_shape(hunan) +\n        tm_polygons(\"lag_sum GDPPC\")\n\ntmap_arrange(gdppc, lag_sum_gdppc)\n\n\n\n\n\n\n3 Spatial window average\nThe diagonal component is included in the spatial window average, which uses weights that are standardized by row.\nBefore allocating weights in R, we must return to the neighbours structure and add the diagonal element, the include.self() method from spdep package is used to accomplish that\n\nwm_q_w_diagonal = wm_q\ninclude.self(wm_q_w_diagonal)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nwm_q_w_diagonal = nb2listw(wm_q_w_diagonal) #compute the weights\nwm_q_w_diagonal\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nWe will then use lag.listw() to create the lag variable from the weight structure and GDPPC variable\n\nlag_w_avg_gdppc = lag.listw(wm_q_w_diagonal, hunan$GDPPC)\nlag_w_avg_gdppc\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame()\n\nlag.list.winavg = list(hunan$County, lag.listw(wm_q_w_diagonal, hunan$GDPPC))\nlag.list.winavg.res = as.data.frame(lag.list.winavg)\ncolnames(lag.list.winavg.res) = c(\"County\", \"lag_window_avg GDPPC\")\n\nUsing the code below, we can append the spatial window average GDPPC values to the Hunan sf data frame.\n\nhunan = left_join(hunan, lag.list.winavg.res)\n\nJoining, by = \"County\"\n\n\nWe can plot the GDPPC and window average GDPPC for comparison using the code below\n\nwin_avg_gdppc = tm_shape(hunan) +\n        tm_polygons(\"lag_window_avg GDPPC\")\n\ntmap_arrange(gdppc, win_avg_gdppc)\n\n\n\n\n\n\n4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo do this we assign binary weights to the neighbour structure that includes the diagonal element, similar to the one done in Spatial lag as a sum of neighboring values\n\nwm_q_w_diagonal = wm_q\ninclude.self(wm_q_w_diagonal)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nb_weights_winsum = lapply(wm_q_w_diagonal, function(x) 0*x + 1)\nb_weights_winsum[1]\n\n[[1]]\n[1] 1 1 1 1 1\n\n\nSimilar to the one done in Spatial lag as a sum of neighboring values, we use nb2listw() and glist parameter to explicitly assign weight values.\n\nb_weights_winsum2 = nb2listw(wm_q_w_diagonal, glist=b_weights_winsum, style=\"B\")\nb_weights_winsum2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the new weight structure, the new lag variable can be derived by using lag.listw()\n\nw_sum_gdppc = list(hunan$County, lag.listw(b_weights_winsum2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame()\n\nw_sum_gdppc.res = as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) = c(\"County\", \"w_sum GDPPC\")\n\nUsing the code below, we can append the spatial window sum GDPPC values to the Hunan sf data frame.\n\nhunan = left_join(hunan, w_sum_gdppc.res)\n\nJoining, by = \"County\"\n\n\nWe can plot the GDPPC and window sum GDPPC for comparison using the code below\n\nwin_sum_gdppc = tm_shape(hunan) +\n        tm_polygons(\"w_sum GDPPC\")\n\ntmap_arrange(gdppc, win_sum_gdppc)"
  },
  {
    "objectID": "In-Class_Ex1/In-class_Ex1.html#reference",
    "href": "In-Class_Ex1/In-class_Ex1.html#reference",
    "title": "In Class Exercise 1 - Chp 3 Applications of Spatial Weights",
    "section": "Reference",
    "text": "Reference\nKam T.S (2022), R for Geospatial Data Science and Analytics, Chapter 3 Spatial Weights and Applications\nhttps://r4gdsa.netlify.app/chap03.html\nBivand R (n.d) Spatial weights for neighbours lists\nhttps://r-spatial.github.io/spdep/reference/nb2listw.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624 Geospatial Analytics",
    "section": "",
    "text": "Welcome to ISSS624 Geospatial Analytics Applications.\nThis site will document my learning Journey"
  },
  {
    "objectID": "Take-Home_Ex1/Take-Home_Ex1.html",
    "href": "Take-Home_Ex1/Take-Home_Ex1.html",
    "title": "Take Home Exercise 1 - Investigation of Water points in Nigeria",
    "section": "",
    "text": "For humanity, water is a valuable resource. To maintain good health, people need access to clean water. It guarantees peace and security, creates a healthy environment, and supports a sustainable economy. However, there is insufficient clean water for more than 40% of the world’s population. UN-Water predicts that by 2025, 1.8 billion people would reside in areas with a complete water shortage. Food security is one of the many areas that are seriously threatened by the water crisis. About 70% of the freshwater that is available on Earth is used for agriculture.\nWater scarcities and poor water quality are worst in developing nations. Inadequate water and sanitation systems are a contributing factor in up to 80% of diseases in impoverished countries.\nDespite technological advancements, supplying clean water to rural communities remains a significant development challenge in many nations worldwide, particularly in those of the continent of Africa.\nIn this study, appropriate global and local measures of spatial Association techniques will be employed to reveal the spatial patterns of Non Functional water points. In this assignment, we will investigate Nigeria’s Local Government Area (LGA)"
  },
  {
    "objectID": "Take-Home_Ex1/Take-Home_Ex1.html#getting-started",
    "href": "Take-Home_Ex1/Take-Home_Ex1.html#getting-started",
    "title": "Take Home Exercise 1 - Investigation of Water points in Nigeria",
    "section": "Getting Started",
    "text": "Getting Started\nFirst, the required packages are loaded into the R environment . The required packages are sf, spdep, tmap & tidyverse, funModeling with the code below:\n\npacman::p_load(sf,tidyverse,spdep, tmap, funModeling)\n\n\nSpatial Data\nThe spatial dataset used in this assignment is the Nigeria Level-2 Administrative Boundary spatial dataset\nWe will load the spatial features by using st_read() from the sf package\nAs the data is in WSG-84 format, we set crs to 4326.\nAs we need to perform the intersect function later to combine the water points data, we will not use st_transform() as it may produce outputs with missing points post transformation.\n\nnga = st_read(dsn = \"data/geospatial\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\",\n               crs = 4326)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `D:\\Allanckw\\ISSS624\\Take-Home_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n#nigeria_lga_sf = st_transform(nigeria_lga_sf, crs=4326) cause missing points\nst_crs(nga)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nWe can examine how the base map looks like by using the tmap package\n\ntm_shape(nga) + \n  \n  tm_borders(alpha=0.5) + \n  tm_compass(type=\"8star\", size=2) +\n  tm_scale_bar() +\n  tm_grid (alpha=0.2) +\n  tm_layout(main.title=\"Map of Nigeria LGA\", \n            main.title.position=\"center\", \n            main.title.size=1.2, \n            legend.height = 0.35, \n            legend.width = 0.35, \n            frame = TRUE) \n\n\n\n\n\n\nAspatial Data\n\nCleaning the Data\nThe aspatial dataset used in this assignment is the water point data exchange dataset found in WPdx Global Data Repositories. Data is filtered on the web portal to only keep Nigeria and the file is saved as NigeriaWaterPoints_Raw.csv\nAs we are only interested in the functionality of the water point, it is important to capture fields that may affect the functionality\n\nLGA: The area we are interested in\nState: The state of the LGA of Nigeria\nFunctional: Whether it is functional or not\nmanagement: who manages it?\nQuality: what is the quality?\nWater Source Category: where the water came from?\nWater Tech Category: What technology is used?\nlatitude\nlongitude\n\nTo load the raw data file, we use the read_csv function\n\nwpdx_raw = read_csv(\"data/aspatial/NigeriaWaterPoints_Raw.csv\") \n\nMost of the columns are irrelevant, so we will perform the following:\n\nkeep the columns we want to clean it up by specifying the columns with one to retain with subset\nrenaming the columns using rename_with\nReplace all the NA with unknown for columns with NA value present\n\n\nretain_cols <- c('#clean_adm2', '#clean_adm1', '#status_clean', '#management_clean', '#subjective_quality', '#fecal_coliform_presence', '#water_source_category', '#water_tech_category', '#lat_deg', '#lon_deg' )\n\nnew_col_names <- c('LGA', 'State', 'Functional', 'Management', 'Quality', 'presence_of_fecal_coliform', 'Water_Source_Category', 'Water_Tech_Category', 'latitude', 'longitude')\n\nwpdx_clean = subset(wpdx_raw, select = (names(wpdx_raw) %in% retain_cols)) %>%  rename_with(~ new_col_names, all_of(retain_cols)) %>% \nreplace_na(list(Functional = \"Unknown\", Management = \"Unknown\", Quality = \"Unknown\", Water_Source_Category = \"Unknown\", Water_Tech_Category = \"Unknown\"))\n\nWe save the clean file with saveRDS(), the file will be reduced to 1.6MB from the 144MB raw file that we downloaded.\n\nsaveRDS(wpdx_clean, \"data/aspatial/wpdx_clean.rds\")\n\nWe can then delete the raw file from the project and retrieve the saved RDS file using readRDS()\n\nwpdx_clean = readRDS(\"data/aspatial/wpdx_clean.rds\")\n\n\n\nConverting csv data into spatial features\nWe can use st_as_sfto create a dataframe from the longitude (x) and latitude (y) values. The EPSG 4326 code is used as the dataset is referencing WGS84 geographic coordinate system\n\nwpdx_clean_sf = st_as_sf(wpdx_clean, coords = c(\"longitude\", \"latitude\"), crs=4326)\nst_crs(wpdx_clean_sf)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nWe can then use glimpse() to verify each field’s data type & available values.\nThe results shows that the longitude and latitude values have been converted to a geometry object consisting of the longitude and latitude values as points, with both columns now dropped.\n\nglimpse(wpdx_clean_sf)\n\nRows: 95,008\nColumns: 8\n$ Water_Source_Category <chr> \"Unknown\", \"Well\", \"Well\", \"Well\", \"Well\", \"Well…\n$ Water_Tech_Category   <chr> \"Tapstand\", \"Mechanized Pump\", \"Hand Pump\", \"Unk…\n$ State                 <chr> \"Ekiti\", \"Ogun\", \"Ebonyi\", \"Enugu\", \"Enugu\", \"Be…\n$ LGA                   <chr> \"Moba\", \"Obafemi-Owode\", \"Ohaukwu\", \"Isi-Uzo\", \"…\n$ Management            <chr> \"Unknown\", \"Other\", \"Unknown\", \"Unknown\", \"Unkno…\n$ Functional            <chr> \"Unknown\", \"Functional\", \"Unknown\", \"Unknown\", \"…\n$ Quality               <chr> \"Unknown\", \"Acceptable quality\", \"Unknown\", \"Unk…\n$ geometry              <POINT [°]> POINT (5.12 7.98), POINT (3.597668 6.96453…\n\n\n\n\nAggregate the Data\nThe code below uses freq() of the funModeling package to display the distribution of functional field in wpdx_clean_sf\n\nfreq(data=wpdx_clean_sf, input = 'Functional')\n\n\n\n\n                        Functional frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                          Unknown     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\nAfter finding its classification, we will need to aggregate them into functional, non functional and unknown. We will create new data frame to store them by using the filter function\n\nfunc_list = c(\"Functional\", \"Functional but needs repair\", \"Functional but not in use\")\nwpt_functional = wpdx_clean_sf %>%\n  filter(Functional %in% func_list)\n\nwpt_non_functional = wpdx_clean_sf %>%\n  filter(!Functional %in% c(func_list, \"Unknown\"))\n\nwpt_unknown = wpdx_clean_sf %>%\n  filter(Functional %in% \"Unknown\")\n\nWe can use st_intersects() to find common data points between geographical datasets. In our case we need to find the common points in between the Nigeria’s LGA and the water points\nThe below code does 4 things\n\nIt intersects the Nigeria LGA dataset (nga dataframe) with the water point dataset (wpdx_clean_sf dataframe) and produce a new column to denote the total number of water points in the area (Total wpt).\nThe result of 1 is piped to add 3 columns to denote the number of functional, non functional and unknown water points in the area to produce wpt functional, wpt non functional and wpt unknown respectively\nWe will also add 2 new columns to find the percentage of functional and non functional water points\nSelect appropriate columns required which are the LGA area and LGA code (Column 3 & 4), Administration Level 1 Area and Administration Level 1 Code (Column 9 & 10), the columns that was added and the geometry multipolygon objects (Column 18 to 23).\n\n\nnga_wp <- nga %>% \n  #combine nga with water point sf\n  mutate(`total wpt` = lengths(\n    st_intersects(nga, wpdx_clean_sf))) %>%\n  #add columns to produce no. of functional, non functional and unknown points\n  mutate(`wpt functional` = lengths(\n    st_intersects(nga, wpt_functional))) %>%\n  mutate(`wpt non functional` = lengths(\n    st_intersects(nga, wpt_non_functional))) %>%\n  mutate(`wpt unknown` = lengths(\n    st_intersects(nga, wpt_unknown))) %>%\n  #add columns to compute %\n  mutate(pct_functional = `wpt functional`/`total wpt`) %>%\n  mutate(`pct_non-functional` = `wpt non functional`/`total wpt`) %>%\n  select(3:4, 9:10, 18:23)"
  },
  {
    "objectID": "Take-Home_Ex1/Take-Home_Ex1.html#visualising-the-spatial-dsitribution-of-water-points",
    "href": "Take-Home_Ex1/Take-Home_Ex1.html#visualising-the-spatial-dsitribution-of-water-points",
    "title": "Take Home Exercise 1 - Investigation of Water points in Nigeria",
    "section": "Visualising the spatial dsitribution of water points",
    "text": "Visualising the spatial dsitribution of water points\nWe will find breaks of the respective distributions by using the summary statistics using percentiles\n\nsummary(nga_wp$`total wpt`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0    45.0    96.0   122.7   168.8   894.0 \n\nsummary(nga_wp$`wpt functional`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   17.00   45.50   67.36   87.75  752.00 \n\nsummary(nga_wp$`wpt non functional`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   12.25   34.00   41.60   60.75  278.00 \n\nsummary(nga_wp$`wpt unknown`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    0.00   13.76   17.75  219.00 \n\n\nFunctions from the tmap packages is used to produce the map\n\nwp_total = tm_shape(nga_wp) + \n  tm_fill(\"total wpt\", \n          palette =\"Reds\", breaks = c(0, 45, 96, 127, 168, 894)) + \n  tm_borders(alpha=0.5) + \n  #tm_compass(type=\"8star\", size=2) +\n  #tm_scale_bar() +\n  tm_grid (alpha=0.2) +\n  tm_layout(main.title=\"Total WP\", \n            main.title.position=\"center\", \n            main.title.size=1.2, \n            legend.height = 0.35, \n            legend.width = 0.35, \n            frame = TRUE) \n\nwp_functional = tm_shape(nga_wp) + \n  tm_fill(\"wpt functional\", \n          palette =\"Reds\", breaks = c(0, 17, 46, 88, 752)) + \n  tm_borders(alpha=0.5) + \n  #tm_compass(type=\"8star\", size=2) +\n  #tm_scale_bar() +\n  tm_grid (alpha=0.2) +\n  tm_layout(main.title=\"functional WP\", \n            main.title.position=\"center\", \n            main.title.size=1.2, \n            legend.height = 0.35, \n            legend.width = 0.35, \n            frame = TRUE) \n\nwp_nonfunctional = tm_shape(nga_wp) + \n  tm_fill(\"wpt non functional\", \n          palette =\"Reds\", breaks = c(0, 17, 46, 67, 88)) + \n  tm_borders(alpha=0.5) + \n  #tm_compass(type=\"8star\", size=2) +\n  #tm_scale_bar() +\n  tm_grid (alpha=0.2) +\n  tm_layout(main.title=\"non functional WP\", \n            main.title.position=\"center\", \n            main.title.size=1.2, \n            legend.height = 0.35, \n            legend.width = 0.35, \n            frame = TRUE) \n\nwp_Unknown = tm_shape(nga_wp) + \n  tm_fill(\"wpt unknown\", \n          palette =\"Reds\", breaks = c(0, 14, 18, 219)) + \n  tm_borders(alpha=0.5) + \n  #tm_compass(type=\"8star\", size=2) +\n  #tm_scale_bar() +\n  tm_grid (alpha=0.2) +\n  tm_layout(main.title=\"unknown status\", \n            main.title.position=\"center\", \n            main.title.size=1.2, \n            legend.height = 0.35, \n            legend.width = 0.35, \n            frame = TRUE) \n\nFinally, we will use the tmap_arrange() method to create a 2x2 matrix to display the maps\n\ntmap_arrange(wp_functional, wp_nonfunctional, wp_Unknown, wp_total, asp=1, ncol=2)\n\n\n\n\nTBC"
  }
]